{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prgr\n",
      "15943\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from dataPre import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import os,sys\n",
    "import json\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# import re\n",
    "import math\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# embeddings = None\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(attention_model,train_loader,criterion,optimizer,epochs = 5,use_regularization = False,C=0,clip=False):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            train_loader    : {DataLoader} training data loaded into a dataloader\n",
    "            optimizer       :  optimizer\n",
    "            criterion       :  loss function. Must be BCELoss for binary_classification and NLLLoss for multiclass\n",
    "            epochs          : {int} number of epochs\n",
    "            use_regularizer : {bool} use penalization or not\n",
    "            C               : {int} penalization coeff\n",
    "            clip            : {bool} use gradient clipping or not\n",
    "       \n",
    "        Returns:\n",
    "            accuracy and losses of the model\n",
    "        \"\"\"\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for i in range(epochs):\n",
    "        print(\"Running EPOCH\",i+1)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        correct = 0\n",
    "        for batch_idx,(lines, contactmap,properties) in enumerate(train_loader):  \n",
    "            input, seq_lengths, y = make_variables(lines, properties,smiles_letters)\n",
    "            attention_model.hidden_state = attention_model.init_hidden()\n",
    "            contactmap = create_variable(contactmap)\n",
    "            y_pred,att = attention_model(input,contactmap)\n",
    "            #penalization AAT - I\n",
    "            if use_regularization:\n",
    "                attT = att.transpose(1,2)\n",
    "                identity = torch.eye(att.size(1))\n",
    "                identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,att.size(1),att.size(1))).cuda()\n",
    "                penal = attention_model.l2_matrix_norm(att@attT - identity)\n",
    "            if not bool(attention_model.type) :\n",
    "                #binary classification\n",
    "                #Adding a very small value to prevent BCELoss from outputting NaN's\n",
    "                correct+=torch.eq(torch.round(y_pred.type(torch.DoubleTensor).squeeze(1)),y.type(torch.DoubleTensor)).data.sum()\n",
    "                if use_regularization:\n",
    "                    loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1),y.type(torch.DoubleTensor))+(C * penal.cpu()/train_loader.batch_size)\n",
    "                else:\n",
    "                    loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1),y.type(torch.DoubleTensor))\n",
    "            total_loss+=loss.data\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() #retain_graph=True\n",
    "           \n",
    "            #gradient clipping\n",
    "            if clip:\n",
    "                torch.nn.utils.clip_grad_norm(attention_model.parameters(),0.5)\n",
    "            optimizer.step()\n",
    "            n_batches+=1\n",
    "            if batch_idx %20000==0: \n",
    "                print(batch_idx)\n",
    "                \n",
    "        avg_loss = total_loss/n_batches\n",
    "        acc = correct.numpy()/(len(train_loader.dataset))\n",
    "        \n",
    "        losses.append(avg_loss)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        print(\"avg_loss is\",avg_loss)\n",
    "        print(\"train ACC = \",acc)\n",
    "        \n",
    "        torch.save(attention_model.state_dict(), './model_pkl/DUDE/DUDE30Res-fold3-%d.pkl'%(i+1))\n",
    "    return losses,accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROCE(predList,targetList,roceRate):\n",
    "    p = sum(targetList)\n",
    "    n = len(targetList) - p\n",
    "    predList = [[index,x] for index,x in enumerate(predList)]\n",
    "    predList = sorted(predList,key = lambda x:x[1],reverse = True)\n",
    "    tp1 = 0\n",
    "    fp1 = 0\n",
    "    maxIndexs = []\n",
    "    for x in predList:\n",
    "        if(targetList[x[0]] == 1):\n",
    "            tp1 += 1\n",
    "        else:\n",
    "            fp1 += 1\n",
    "            if(fp1>((roceRate*n)/100)):\n",
    "                break\n",
    "    roce = (tp1*n)/(p*fp1)\n",
    "    return roce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(attention_model,test_loader,criterion,use_regularization = False):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            attention_model : {object} model\n",
    "            train_loader    : {DataLoader} training data loaded into a dataloader\n",
    "            optimizer       :  optimizer\n",
    "            criterion       :  loss function. Must be BCELoss for binary_classification and NLLLoss for multiclass\n",
    "            epochs          : {int} number of epochs\n",
    "            use_regularizer : {bool} use penalization or not\n",
    "            C               : {int} penalization coeff\n",
    "            clip            : {bool} use gradient clipping or not\n",
    "        Returns:\n",
    "            accuracy and losses of the model\n",
    "        \"\"\"\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    print('test begin ...')\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    correct = 0\n",
    "    all_pred = np.array([])\n",
    "    all_target = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,(lines, contactmap,properties) in enumerate(test_loader):\n",
    "            input, seq_lengths, y = make_variables(lines, properties,smiles_letters)\n",
    "            attention_model.hidden_state = attention_model.init_hidden()\n",
    "            contactmap = contactmap.cuda()\n",
    "            y_pred,att = attention_model(input,contactmap)\n",
    "            if not bool(attention_model.type) :\n",
    "                #binary classification\n",
    "                #Adding a very small value to prevent BCELoss from outputting NaN's\n",
    "                pred = torch.round(y_pred.type(torch.DoubleTensor).squeeze(1))\n",
    "                correct+=torch.eq(torch.round(y_pred.type(torch.DoubleTensor).squeeze(1)),y.type(torch.DoubleTensor)).data.sum()\n",
    "                all_pred=np.concatenate((all_pred,y_pred.data.cpu().squeeze(1).numpy()),axis = 0)\n",
    "                all_target = np.concatenate((all_target,y.data.cpu().numpy()),axis = 0)\n",
    "                if use_regularization:\n",
    "                    loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1),y.type(torch.DoubleTensor))+(C * penal.cpu()/train_loader.batch_size)\n",
    "                else:\n",
    "                    loss = criterion(y_pred.type(torch.DoubleTensor).squeeze(1),y.type(torch.DoubleTensor))\n",
    "            total_loss+=loss.data\n",
    "            n_batches+=1\n",
    "    testSize = round(len(test_loader.dataset),3)\n",
    "    testAcc = round(correct.numpy()/(n_batches*test_loader.batch_size),3)\n",
    "    testRecall = round(metrics.recall_score(all_target,np.round(all_pred)),3)\n",
    "    testPrecision = round(metrics.precision_score(all_target,np.round(all_pred)),3)\n",
    "    testAuc = round(metrics.roc_auc_score(all_target, all_pred),3)\n",
    "    print(\"AUPR = \",metrics.average_precision_score(all_target, all_pred))\n",
    "    testLoss = round(total_loss.item()/n_batches,5)\n",
    "    print(\"test size =\",testSize,\"  test acc =\",testAcc,\"  test recall =\",testRecall,\"  test precision =\",testPrecision,\"  test auc =\",testAuc,\"  test loss = \",testLoss)\n",
    "    roce1 = round(getROCE(all_pred,all_target,0.5),2)\n",
    "    roce2 = round(getROCE(all_pred,all_target,1),2)\n",
    "    roce3 = round(getROCE(all_pred,all_target,2),2)\n",
    "    roce4 = round(getROCE(all_pred,all_target,5),2)\n",
    "    print(\"roce0.5 =\",roce1,\"  roce1.0 =\",roce2,\"  roce2.0 =\",roce3,\"  roce5.0 =\",roce4)\n",
    "    return testAcc,testRecall,testPrecision,testAuc,testLoss,all_pred,all_target,roce1,roce2,roce3,roce4\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classfication(attention_model,train_loader,epochs=20,use_regularization=True,C=1.0,clip=True):\n",
    "    attention_model.cuda()\n",
    "    loss = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(attention_model.parameters(),lr=0.0007)\n",
    "    losses,accs = train(attention_model,train_loader,loss,optimizer,epochs,use_regularization,C,clip)\n",
    "    return losses,accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running EPOCH 1\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.3298, dtype=torch.float64)\n",
      "train ACC =  0.9331430114578912\n",
      "Running EPOCH 2\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.1281, dtype=torch.float64)\n",
      "train ACC =  0.9761197484664943\n",
      "Running EPOCH 3\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0810, dtype=torch.float64)\n",
      "train ACC =  0.9864974345125573\n",
      "Running EPOCH 4\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0658, dtype=torch.float64)\n",
      "train ACC =  0.9886964237490837\n",
      "Running EPOCH 5\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0529, dtype=torch.float64)\n",
      "train ACC =  0.9914740943636434\n",
      "Running EPOCH 6\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0450, dtype=torch.float64)\n",
      "train ACC =  0.9929015084294588\n",
      "Running EPOCH 7\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0438, dtype=torch.float64)\n",
      "train ACC =  0.9937116623587053\n",
      "Running EPOCH 8\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0430, dtype=torch.float64)\n",
      "train ACC =  0.9935187685660275\n",
      "Running EPOCH 9\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0389, dtype=torch.float64)\n",
      "train ACC =  0.9949847613903785\n",
      "Running EPOCH 10\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0345, dtype=torch.float64)\n",
      "train ACC =  0.9953319702171984\n",
      "Running EPOCH 11\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0353, dtype=torch.float64)\n",
      "train ACC =  0.995447706492805\n",
      "Running EPOCH 12\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0383, dtype=torch.float64)\n",
      "train ACC =  0.9949847613903785\n",
      "Running EPOCH 13\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0286, dtype=torch.float64)\n",
      "train ACC =  0.9962964391805872\n",
      "Running EPOCH 14\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0293, dtype=torch.float64)\n",
      "train ACC =  0.9963350179391227\n",
      "Running EPOCH 15\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0243, dtype=torch.float64)\n",
      "train ACC =  0.9967593842830138\n",
      "Running EPOCH 16\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0215, dtype=torch.float64)\n",
      "train ACC =  0.9970294355927626\n",
      "Running EPOCH 17\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0342, dtype=torch.float64)\n",
      "train ACC =  0.9960263878708383\n",
      "Running EPOCH 18\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0260, dtype=torch.float64)\n",
      "train ACC =  0.9970294355927626\n",
      "Running EPOCH 19\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0207, dtype=torch.float64)\n",
      "train ACC =  0.9972994869025115\n",
      "Running EPOCH 20\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0184, dtype=torch.float64)\n",
      "train ACC =  0.9981482195902935\n",
      "Running EPOCH 21\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0231, dtype=torch.float64)\n",
      "train ACC =  0.9970294355927626\n",
      "Running EPOCH 22\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0162, dtype=torch.float64)\n",
      "train ACC =  0.9978781682805448\n",
      "Running EPOCH 23\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0265, dtype=torch.float64)\n",
      "train ACC =  0.9971065931098337\n",
      "Running EPOCH 24\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0225, dtype=torch.float64)\n",
      "train ACC =  0.9975695382122604\n",
      "Running EPOCH 25\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0159, dtype=torch.float64)\n",
      "train ACC =  0.9980710620732225\n",
      "Running EPOCH 26\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0155, dtype=torch.float64)\n",
      "train ACC =  0.9983796921415069\n",
      "Running EPOCH 27\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0240, dtype=torch.float64)\n",
      "train ACC =  0.9974152231781181\n",
      "Running EPOCH 28\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0181, dtype=torch.float64)\n",
      "train ACC =  0.9984182709000424\n",
      "Running EPOCH 29\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0225, dtype=torch.float64)\n",
      "train ACC =  0.9978010107634736\n",
      "Running EPOCH 30\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0199, dtype=torch.float64)\n",
      "train ACC =  0.9978781682805448\n",
      "Running EPOCH 31\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0191, dtype=torch.float64)\n",
      "train ACC =  0.998032483314687\n",
      "Running EPOCH 32\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0181, dtype=torch.float64)\n",
      "train ACC =  0.998109640831758\n",
      "Running EPOCH 33\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0187, dtype=torch.float64)\n",
      "train ACC =  0.997685274487867\n",
      "Running EPOCH 34\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0209, dtype=torch.float64)\n",
      "train ACC =  0.9979939045561513\n",
      "Running EPOCH 35\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0249, dtype=torch.float64)\n",
      "train ACC =  0.9976466957293314\n",
      "Running EPOCH 36\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0233, dtype=torch.float64)\n",
      "train ACC =  0.9979553257976158\n",
      "Running EPOCH 37\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0225, dtype=torch.float64)\n",
      "train ACC =  0.997685274487867\n",
      "Running EPOCH 38\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0237, dtype=torch.float64)\n",
      "train ACC =  0.9978781682805448\n",
      "Running EPOCH 39\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0174, dtype=torch.float64)\n",
      "train ACC =  0.9978781682805448\n",
      "Running EPOCH 40\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0256, dtype=torch.float64)\n",
      "train ACC =  0.9979939045561513\n",
      "Running EPOCH 41\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0264, dtype=torch.float64)\n",
      "train ACC =  0.9978010107634736\n",
      "Running EPOCH 42\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0140, dtype=torch.float64)\n",
      "train ACC =  0.9982639558659002\n",
      "Running EPOCH 43\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0172, dtype=torch.float64)\n",
      "train ACC =  0.9978010107634736\n",
      "Running EPOCH 44\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0157, dtype=torch.float64)\n",
      "train ACC =  0.9983025346244357\n",
      "Running EPOCH 45\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0234, dtype=torch.float64)\n",
      "train ACC =  0.9978395895220091\n",
      "Running EPOCH 46\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0160, dtype=torch.float64)\n",
      "train ACC =  0.998109640831758\n",
      "Running EPOCH 47\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0153, dtype=torch.float64)\n",
      "train ACC =  0.9985725859341846\n",
      "Running EPOCH 48\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0203, dtype=torch.float64)\n",
      "train ACC =  0.9975695382122604\n",
      "Running EPOCH 49\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0223, dtype=torch.float64)\n",
      "train ACC =  0.998109640831758\n",
      "Running EPOCH 50\n",
      "0\n",
      "20000\n",
      "avg_loss is tensor(0.0131, dtype=torch.float64)\n",
      "train ACC =  0.9982639558659002\n"
     ]
    }
   ],
   "source": [
    "LSTM_HID_DIM = 64\n",
    "D_A = 32\n",
    "R_HEAD = 10\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "\n",
    "attention_model = DrugVQA(batch_size=BATCH_SIZE,lstm_hid_dim=LSTM_HID_DIM,d_a = D_A,r=R_HEAD,block = ResidualBlock,\n",
    "                          n_chars_smi = N_CHARS_SMI,n_chars_seq = N_CHARS_SEQ,num_classes=[2, 2, 2, 2],n_classes=1)\n",
    "losses,accs = binary_classfication(attention_model,train_loader=train_loader,epochs=EPOCHS,use_regularization=False,C=0.03,clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "6\n",
      "-------------------------------testEpoch-------------------------------- DUDE30Res-fold3-15.pkl\n",
      "\n",
      " current test protein: tryb1\n",
      "test begin ...\n",
      "AUPR =  0.5229681978798587\n",
      "test size = 7798   test acc = 0.951   test recall = 1.0   test precision = 0.279   test auc = 0.991   test loss =  0.6757\n",
      "roce0.5 = 55.67   roce1.0 = 59.07   roce2.0 = 49.68   roce5.0 = 19.97\n",
      "\n",
      " current test protein: mcr\n",
      "test begin ...\n",
      "AUPR =  0.9550806283401287\n",
      "test size = 5244   test acc = 0.997   test recall = 0.968   test precision = 0.883   test auc = 0.998   test loss =  0.03005\n",
      "roce0.5 = 195.97   roce1.0 = 97.98   roce2.0 = 48.99   roce5.0 = 19.75\n",
      "\n",
      " current test protein: cxcr4\n",
      "test begin ...\n",
      "AUPR =  0.24205187283957214\n",
      "test size = 3446   test acc = 0.989   test recall = 0.125   test precision = 0.714   test auc = 0.782   test loss =  0.15025\n",
      "roce0.5 = 37.84   roce1.0 = 24.33   roce2.0 = 16.04   roce5.0 = 11.45\n",
      "-------------------------------testEpoch-------------------------------- DUDE30Res-fold3-25.pkl\n",
      "\n",
      " current test protein: tryb1\n",
      "test begin ...\n",
      "AUPR =  0.4572074706292631\n",
      "test size = 7798   test acc = 0.95   test recall = 0.993   test precision = 0.274   test auc = 0.988   test loss =  0.77179\n",
      "roce0.5 = 31.81   roce1.0 = 44.98   roce2.0 = 43.97   roce5.0 = 19.84\n",
      "\n",
      " current test protein: mcr\n",
      "test begin ...\n",
      "AUPR =  0.9618882680757346\n",
      "test size = 5244   test acc = 0.996   test recall = 0.947   test precision = 0.864   test auc = 0.998   test loss =  0.03232\n",
      "roce0.5 = 191.76   roce1.0 = 95.88   roce2.0 = 47.94   roce5.0 = 19.54\n",
      "\n",
      " current test protein: cxcr4\n",
      "test begin ...\n",
      "AUPR =  0.40418054310981033\n",
      "test size = 3446   test acc = 0.99   test recall = 0.175   test precision = 0.778   test auc = 0.895   test loss =  0.13364\n",
      "roce0.5 = 66.23   roce1.0 = 53.52   roce2.0 = 33.32   roce5.0 = 13.94\n",
      "-------------------------------testEpoch-------------------------------- DUDE30Res-fold3-35.pkl\n",
      "\n",
      " current test protein: tryb1\n",
      "test begin ...\n",
      "AUPR =  0.5966948752330566\n",
      "test size = 7798   test acc = 0.966   test recall = 0.973   test precision = 0.356   test auc = 0.992   test loss =  0.46904\n",
      "roce0.5 = 86.15   roce1.0 = 75.18   roce2.0 = 48.33   roce5.0 = 19.43\n",
      "\n",
      " current test protein: mcr\n",
      "test begin ...\n",
      "AUPR =  0.9306614111769963\n",
      "test size = 5244   test acc = 0.997   test recall = 0.926   test precision = 0.906   test auc = 0.998   test loss =  0.04258\n",
      "roce0.5 = 191.76   roce1.0 = 95.88   roce2.0 = 47.94   roce5.0 = 19.75\n",
      "\n",
      " current test protein: cxcr4\n",
      "test begin ...\n",
      "AUPR =  0.413676836896618\n",
      "test size = 3446   test acc = 0.989   test recall = 0.125   test precision = 0.714   test auc = 0.916   test loss =  0.15915\n",
      "roce0.5 = 75.69   roce1.0 = 53.52   roce2.0 = 32.09   roce5.0 = 14.94\n",
      "-------------------------------testEpoch-------------------------------- DUDE30Res-fold3-45.pkl\n",
      "\n",
      " current test protein: tryb1\n",
      "test begin ...\n",
      "AUPR =  0.559062445767104\n",
      "test size = 7798   test acc = 0.974   test recall = 0.966   test precision = 0.421   test auc = 0.989   test loss =  0.45756\n",
      "roce0.5 = 87.47   roce1.0 = 72.5   roce2.0 = 47.66   roce5.0 = 19.43\n",
      "\n",
      " current test protein: mcr\n",
      "test begin ...\n",
      "AUPR =  0.9239490697486307\n",
      "test size = 5244   test acc = 0.996   test recall = 0.84   test precision = 0.929   test auc = 0.996   test loss =  0.03003\n",
      "roce0.5 = 177.0   roce1.0 = 91.66   roce2.0 = 46.36   roce5.0 = 19.54\n",
      "\n",
      " current test protein: cxcr4\n",
      "test begin ...\n",
      "AUPR =  0.33823742013654917\n",
      "test size = 3446   test acc = 0.989   test recall = 0.075   test precision = 0.6   test auc = 0.949   test loss =  0.13797\n",
      "roce0.5 = 52.04   roce1.0 = 43.79   roce2.0 = 29.62   roce5.0 = 13.44\n",
      "-------------------------------testEpoch-------------------------------- DUDE30Res-fold3-5.pkl\n",
      "\n",
      " current test protein: tryb1\n",
      "test begin ...\n",
      "AUPR =  0.619952341720832\n",
      "test size = 7798   test acc = 0.905   test recall = 1.0   test precision = 0.166   test auc = 0.994   test loss =  0.84846\n",
      "roce0.5 = 88.8   roce1.0 = 81.9   roce2.0 = 49.68   roce5.0 = 19.97\n",
      "\n",
      " current test protein: mcr\n",
      "test begin ...\n",
      "AUPR =  0.9517173573151405\n",
      "test size = 5244   test acc = 0.994   test recall = 0.947   test precision = 0.754   test auc = 0.992   test loss =  0.03858\n",
      "roce0.5 = 187.54   roce1.0 = 93.77   roce2.0 = 46.89   roce5.0 = 19.11\n",
      "\n",
      " current test protein: cxcr4\n",
      "test begin ...\n",
      "AUPR =  0.41124425791888103\n",
      "test size = 3446   test acc = 0.99   test recall = 0.2   test precision = 0.889   test auc = 0.961   test loss =  0.09202\n",
      "roce0.5 = 56.77   roce1.0 = 46.22   roce2.0 = 28.38   roce5.0 = 13.44\n",
      "-------------------------------testEpoch-------------------------------- DUDE30Res-fold3-50.pkl\n",
      "\n",
      " current test protein: tryb1\n",
      "test begin ...\n",
      "AUPR =  0.38880582719534135\n",
      "test size = 7798   test acc = 0.939   test recall = 0.986   test precision = 0.235   test auc = 0.984   test loss =  1.03385\n",
      "roce0.5 = 35.78   roce1.0 = 32.22   roce2.0 = 36.59   roce5.0 = 19.57\n",
      "\n",
      " current test protein: mcr\n",
      "test begin ...\n",
      "AUPR =  0.7967235173482686\n",
      "test size = 5244   test acc = 0.985   test recall = 0.989   test precision = 0.547   test auc = 0.997   test loss =  0.18134\n",
      "roce0.5 = 191.76   roce1.0 = 97.98   roce2.0 = 48.99   roce5.0 = 19.75\n",
      "\n",
      " current test protein: cxcr4\n",
      "test begin ...\n",
      "AUPR =  0.5708190211063435\n",
      "test size = 3446   test acc = 0.993   test recall = 0.5   test precision = 0.833   test auc = 0.962   test loss =  0.09206\n",
      "roce0.5 = 104.07   roce1.0 = 60.82   roce2.0 = 38.26   roce5.0 = 17.93\n"
     ]
    }
   ],
   "source": [
    "LSTM_HID_DIM = 64\n",
    "D_A = 32\n",
    "R_HEAD = 10\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "attention_model = DrugVQA(batch_size=BATCH_SIZE,lstm_hid_dim=LSTM_HID_DIM,d_a = D_A,r=R_HEAD,block = ResidualBlock,\n",
    "                          n_chars_smi = N_CHARS_SMI,n_chars_seq = N_CHARS_SEQ,num_classes=[2, 2, 2, 2],n_classes=1)\n",
    "attention_model.cuda()\n",
    "testpklPath =  './model_pkl/DUDE/'\n",
    "testpkl = os.listdir(testpklPath)\n",
    "print(len(testpkl))\n",
    "testpkl = [x for x in testpkl if 'DUDE30Res-fold3' in x and '5' in x]\n",
    "testpkl = sorted(testpkl)\n",
    "print(len(testpkl))\n",
    "resultDict = {}\n",
    "for path in testpkl:\n",
    "    resultProteinDict = {}\n",
    "    attention_model.load_state_dict(torch.load('./model_pkl/DUDE/'+path,map_location=lambda storage,loc:storage.cuda(4)))\n",
    "    loss = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(attention_model.parameters())\n",
    "    print('-------------------------------testEpoch--------------------------------',path)\n",
    "    testProteinList = ['tryb1_2zebA_full','mcr_2oaxE_full', 'cxcr4_3oduA_full']\n",
    "    for x in testProteinList:\n",
    "        print('\\n current test protein:',x.split('_')[0])\n",
    "        data = dataDict[x]\n",
    "        test_dataset = ProDataset(dataSet = data,seqContactDict = seqContactDict)\n",
    "        test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=1, shuffle=True,drop_last = True)\n",
    "        \n",
    "        testAcc,testRecall,testPrecision,testAuc,testLoss,all_pred,all_target,roce1,roce2,roce3,roce4= test(attention_model,test_loader,loss)\n",
    "        resultProteinDict[x] = [testAcc,testRecall,testPrecision,testAuc,testLoss,roce1,roce2,roce3,roce4]\n",
    "    resultDict[path] = resultProteinDict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
